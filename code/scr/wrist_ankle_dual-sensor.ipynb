{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18711,
     "status": "ok",
     "timestamp": 1759085677935,
     "user": {
      "displayName": "Chen Yi",
      "userId": "15055353069078412577"
     },
     "user_tz": -60
    },
    "id": "fRHpgoKOyfN0",
    "outputId": "3d5764d1-d814-4580-e02f-8b4e3290a997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnRzf4P9goEK"
   },
   "source": [
    "### Ankle - Wrist - Dual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tsfel+4 (with Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1972498,
     "status": "ok",
     "timestamp": 1759102067156,
     "user": {
      "displayName": "Chen Yi",
      "userId": "15055353069078412577"
     },
     "user_tz": -60
    },
    "id": "y7mJKBDtglPi",
    "outputId": "048acd5e-bdbd-41c8-f27e-3f9b0909f0ab"
   },
   "outputs": [],
   "source": [
    "# 折均值±std + CM(counts/normalized) + Report\n",
    "# 导入\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, balanced_accuracy_score,\n",
    "    precision_score, recall_score, classification_report,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 数据路径\n",
    "TRAIN_CSV = \"/content/drive/My Drive/final_project/ankle_wrist_only/train_filled.csv\"\n",
    "VAL_CSV = \"/content/drive/My Drive/final_project/ankle_wrist_only/val_filled.csv\"\n",
    "\n",
    "# 列名\n",
    "SUBJECT_COL = \"Subject\"\n",
    "ACTIVITY_COL = \"Activity\"\n",
    "\n",
    "# 人口学特征\n",
    "DEMOGRAPHIC_CAT_COLS = []\n",
    "DEMOGRAPHIC_NUM_COLS = []\n",
    "\n",
    "# 要跑的模态\n",
    "MODALITIES_TO_RUN = [\"wrist\", \"ankle\", \"dual\"]\n",
    "MODALITY_DISPLAY = {\"wrist\": \"wrist\", \"ankle\": \"ankle\", \"dual\": \"dual\"}\n",
    "\n",
    "# Baseline\n",
    "SEED = 42\n",
    "PCA_N_COMPONENTS = 0.6\n",
    "RF_PARAMS = dict(\n",
    "    n_estimators = 200,\n",
    "    max_depth = 3,\n",
    "    min_samples_split = 2,\n",
    "    min_samples_leaf  = 2,\n",
    "    max_features = \"sqrt\",\n",
    "    class_weight = \"balanced\",\n",
    "    random_state = SEED,\n",
    "    n_jobs = -1,\n",
    ")\n",
    "BAGGING_N_ESTIMATORS = 10\n",
    "\n",
    "# 输出目录\n",
    "OUT_DIR_FIGS = \"/content/drive/My Drive/final_project/ankle_wrist_only/final_outputs/dev_figs\"\n",
    "OUT_DIR_REPORTS = \"/content/drive/My Drive/final_project/ankle_wrist_only/final_outputs/dev_reports\"\n",
    "os.makedirs(OUT_DIR_FIGS, exist_ok=True)\n",
    "os.makedirs(OUT_DIR_REPORTS, exist_ok=True)\n",
    "\n",
    "# 工具函数\n",
    "def pick_columns_by_prefix(df, prefixes):\n",
    "    return [c for c in df.columns if any(c.startswith(p) for p in prefixes)]\n",
    "\n",
    "def build_modality_view(df, modality, subject_col, activity_col, demo_cat_cols, demo_num_cols):\n",
    "\n",
    "    d = df.copy().replace([np.inf, -np.inf], np.nan)\n",
    "    assert subject_col in d.columns, f\"缺少列：{subject_col}\"\n",
    "    assert activity_col in d.columns, f\"缺少列：{activity_col}\"\n",
    "\n",
    "    wrist_cols = pick_columns_by_prefix(d, [\"wrist_\"])\n",
    "    ankle_cols = pick_columns_by_prefix(d, [\"ankle_\"])\n",
    "\n",
    "    if modality == \"wrist\":\n",
    "        feat_cols = wrist_cols\n",
    "    elif modality == \"ankle\":\n",
    "        feat_cols = ankle_cols\n",
    "    elif modality == \"dual\": \n",
    "        feat_cols = wrist_cols + [c for c in ankle_cols if c not in wrist_cols]\n",
    "    else:\n",
    "        raise ValueError(\"modality 必须是 'wrist' | 'ankle' | 'dual'\")\n",
    "\n",
    "    demo_cat = [c for c in (demo_cat_cols or []) if c in d.columns]\n",
    "    demo_num = [c for c in (demo_num_cols or []) if c in d.columns]\n",
    "\n",
    "    # 数值特征管道\n",
    "    num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "    transformers = [(\"num\", num_pipe, feat_cols)]\n",
    "\n",
    "    # 分类特征 OHE\n",
    "    if demo_cat:\n",
    "        try:\n",
    "            ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        except TypeError:\n",
    "            ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "        cat_pipe = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", ohe)\n",
    "        ])\n",
    "        transformers.append((\"cat\", cat_pipe, demo_cat))\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers,\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3  \n",
    "    )\n",
    "\n",
    "    used_cols = feat_cols + demo_cat + demo_num\n",
    "    X_raw = d[used_cols].copy()\n",
    "    y = d[activity_col].astype(str).values\n",
    "    groups = d[subject_col].astype(str).values\n",
    "    meta = d[[subject_col, activity_col]].copy()\n",
    "\n",
    "    return X_raw, y, groups, preprocessor, meta, feat_cols\n",
    "\n",
    "def build_fixed_baseline_pipeline(preprocessor):\n",
    "\n",
    "    rf_base = RandomForestClassifier(**RF_PARAMS)\n",
    "    bag = BaggingClassifier(\n",
    "        estimator = rf_base,\n",
    "        n_estimators = BAGGING_N_ESTIMATORS,\n",
    "        random_state = SEED,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"scaler\", StandardScaler(with_mean=True)),\n",
    "        (\"pca\", PCA(n_components=PCA_N_COMPONENTS, random_state=SEED)),\n",
    "        (\"bag\", bag)\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "def plot_cm_counts_and_norm(y_true, y_pred, labels, title_prefix, out_png_prefix):\n",
    "    # counts\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ConfusionMatrixDisplay(cm, display_labels=labels).plot(ax=ax, cmap=\"Blues\", colorbar=True, values_format=\"d\")\n",
    "    ax.set_title(f\"{title_prefix} — Confusion Matrix (Counts)\")\n",
    "    plt.tight_layout()\n",
    "    png_counts = f\"{OUT_DIR_FIGS}/{out_png_prefix}_tsfel_CM_counts.png\"\n",
    "    plt.savefig(png_counts, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # normalized \n",
    "    cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ConfusionMatrixDisplay(cm_norm, display_labels=labels).plot(ax=ax, cmap=\"Blues\", colorbar=True, values_format=\".2f\")\n",
    "    ax.set_title(f\"{title_prefix} — Confusion Matrix (Normalized)\")\n",
    "    plt.tight_layout()\n",
    "    png_norm = f\"{OUT_DIR_FIGS}/{out_png_prefix}_tsfel_CM_normalized.png\"\n",
    "    plt.savefig(png_norm, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return cm, cm_norm, png_counts, png_norm\n",
    "\n",
    "def loso_evaluate_fixed(X_df, y, groups, preprocessor, label_order=None, run_name=\"\"):\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "    metrics_rows = []\n",
    "    y_true_all = np.empty_like(y, dtype=object)\n",
    "    y_pred_all = np.empty_like(y, dtype=object)\n",
    "\n",
    "    # 用固定超参，逐折新建/拟合\n",
    "    for fold_id, (tr, te) in enumerate(logo.split(X_df, y, groups), start=1):\n",
    "        pipe = build_fixed_baseline_pipeline(preprocessor)\n",
    "        pipe.fit(X_df.iloc[tr], y[tr])\n",
    "        pred = pipe.predict(X_df.iloc[te])\n",
    "\n",
    "        y_true_all[te] = y[te]\n",
    "        y_pred_all[te] = pred\n",
    "\n",
    "        row = dict(\n",
    "            fold = fold_id,\n",
    "            subject = \",\".join(sorted(set(groups[te]))),\n",
    "            acc = accuracy_score(y[te], pred),\n",
    "            balAcc = balanced_accuracy_score(y[te], pred),\n",
    "            macroF1 = f1_score(y[te], pred, average=\"macro\", zero_division=0),\n",
    "            prec = precision_score(y[te], pred, average=\"macro\", zero_division=0),\n",
    "            rec = recall_score(y[te], pred, average=\"macro\", zero_division=0),\n",
    "            n = len(te),\n",
    "        )\n",
    "        metrics_rows.append(row)\n",
    "\n",
    "    folds_df = pd.DataFrame(metrics_rows)\n",
    "    m = folds_df[[\"acc\",\"balAcc\",\"macroF1\",\"prec\",\"rec\"]].mean()\n",
    "    s = folds_df[[\"acc\",\"balAcc\",\"macroF1\",\"prec\",\"rec\"]].std(ddof=1)\n",
    "\n",
    "    labels = sorted(np.unique(y)) if label_order is None else label_order\n",
    "    rep = classification_report(y_true_all, y_pred_all, labels=labels, output_dict=True, zero_division=0)\n",
    "    rep_df = pd.DataFrame(rep).T.reset_index().rename(columns={\"index\":\"class\"})\n",
    "\n",
    "    # 保存报告文件\n",
    "    folds_csv = f\"{OUT_DIR_REPORTS}/DEV_Folds__tsfel_{run_name}.csv\"\n",
    "    rep_csv = f\"{OUT_DIR_REPORTS}/DEV_Report_tsfel_{run_name}.csv\"\n",
    "    folds_df.to_csv(folds_csv, index=False)\n",
    "    rep_df.to_csv(rep_csv, index=False)\n",
    "\n",
    "    print(f\"\\n[DEV-LOSO: {run_name}] folds={len(folds_df)} samples={len(y)} subjects={len(np.unique(groups))}\")\n",
    "    print(\"Acc : %.3f ± %.3f\" % (m[\"acc\"],    s[\"acc\"]))\n",
    "    print(\"Balanced Acc : %.3f ± %.3f\" % (m[\"balAcc\"], s[\"balAcc\"]))\n",
    "    print(\"Macro-F1 : %.3f ± %.3f\" % (m[\"macroF1\"], s[\"macroF1\"]))\n",
    "    print(\"Macro-Prec : %.3f ± %.3f\" % (m[\"prec\"],   s[\"prec\"]))\n",
    "    print(\"Macro-Rec : %.3f ± %.3f\" % (m[\"rec\"],    s[\"rec\"]))\n",
    "    print(\"Saved:\", folds_csv)\n",
    "    print(\"Saved:\", rep_csv)\n",
    "\n",
    "    return dict(\n",
    "        folds_df=folds_df, mean=m, std=s,\n",
    "        y_true_all=y_true_all, y_pred_all=y_pred_all,\n",
    "        labels=labels, rep_df=rep_df, rep_csv=rep_csv,\n",
    "    )\n",
    "\n",
    "# 主流程\n",
    "def main():\n",
    "    # 读 DEV（train∪val）\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    val_df = pd.read_csv(VAL_CSV)\n",
    "    DEV_DF = pd.concat([train_df, val_df], ignore_index=True)\n",
    "\n",
    "    # 汇总表（折均值±std）\n",
    "    summary_rows = []\n",
    "\n",
    "    for modality in MODALITIES_TO_RUN:\n",
    "        Xd, yd, gd, pre_d, meta_d, feat_cols = build_modality_view(\n",
    "            DEV_DF, modality, SUBJECT_COL, ACTIVITY_COL,\n",
    "            DEMOGRAPHIC_CAT_COLS, DEMOGRAPHIC_NUM_COLS\n",
    "        )\n",
    "        disp_name = MODALITY_DISPLAY.get(modality, modality)\n",
    "        run_name = f\"LOSO_{disp_name}\"\n",
    "\n",
    "        print(f\"\\n Running LOSO for: {disp_name} | n_samples={len(yd)} | n_features={len(feat_cols)} \")\n",
    "        res = loso_evaluate_fixed(\n",
    "            X_df=Xd, y=yd, groups=gd, preprocessor=pre_d, run_name=run_name\n",
    "        )\n",
    "\n",
    "        # 画并保存 CM（counts + normalized）\n",
    "        title_prefix = f\"{disp_name} [DEV LOSO]\"\n",
    "        out_prefix = f\"DEV_{run_name}\"\n",
    "        cm, cm_norm, png_counts, png_norm = plot_cm_counts_and_norm(\n",
    "            res[\"y_true_all\"], res[\"y_pred_all\"], res[\"labels\"], title_prefix, out_prefix\n",
    "        )\n",
    "        print(\"Saved:\", png_counts)\n",
    "        print(\"Saved:\", png_norm)\n",
    "\n",
    "        # 汇总一行\n",
    "        summary_rows.append({\n",
    "            \"modality\": disp_name,\n",
    "            \"Acc (mean±std)\" : f\"{res['mean']['acc']:.4f} ± {res['std']['acc']:.4f}\",\n",
    "            \"Balanced Acc (mean±std)\": f\"{res['mean']['balAcc']:.4f} ± {res['std']['balAcc']:.4f}\",\n",
    "            \"Macro-F1 (mean±std)\" : f\"{res['mean']['macroF1']:.4f} ± {res['std']['macroF1']:.4f}\",\n",
    "            \"Macro-Prec (mean±std)\" : f\"{res['mean']['prec']:.4f} ± {res['std']['prec']:.4f}\",\n",
    "            \"Macro-Rec (mean±std)\" : f\"{res['mean']['rec']:.4f} ± {res['std']['rec']:.4f}\",\n",
    "            \"n_samples\" : len(yd),\n",
    "            \"n_features\" : len(feat_cols),\n",
    "        })\n",
    "\n",
    "    # 打印与保存汇总表\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    print(\"\\nSummary (DEV LOSO)\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    summary_csv = f\"{OUT_DIR_REPORTS}/DEV_Summary_LOSO_tsfel_.csv\"\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(\"Saved:\", summary_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRD4jgxWrscN"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5Mb7p6tjAGl"
   },
   "source": [
    "#### time-frequency (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 637303,
     "status": "ok",
     "timestamp": 1759102704477,
     "user": {
      "displayName": "Chen Yi",
      "userId": "15055353069078412577"
     },
     "user_tz": -60
    },
    "id": "GXJ40UldjFOP",
    "outputId": "3c1062c6-b2df-4186-a4ae-b6a879520af5"
   },
   "outputs": [],
   "source": [
    "# 折均值±std + CM(counts/normalized) + Report\n",
    "# 导入\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, balanced_accuracy_score,\n",
    "    precision_score, recall_score, classification_report,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 数据路径\n",
    "TRAIN_CSV = \"/content/drive/My Drive/final_project/ankle_wrist_only/7_2_sets/train.csv\"\n",
    "VAL_CSV = \"/content/drive/My Drive/final_project/ankle_wrist_only/7_2_sets/val.csv\"\n",
    "\n",
    "# 列名\n",
    "SUBJECT_COL = \"Subject\"\n",
    "ACTIVITY_COL = \"Activity\"\n",
    "\n",
    "# 人口学特征\n",
    "DEMOGRAPHIC_CAT_COLS = []\n",
    "DEMOGRAPHIC_NUM_COLS = []\n",
    "\n",
    "# 要跑的模态\n",
    "MODALITIES_TO_RUN = [\"wrist\", \"ankle\", \"dual\"]\n",
    "MODALITY_DISPLAY = {\"wrist\": \"wrist\", \"ankle\": \"ankle\", \"dual\": \"dual\"}\n",
    "\n",
    "# Baseline 固定超参数\n",
    "SEED = 42\n",
    "PCA_N_COMPONENTS = 0.6\n",
    "RF_PARAMS = dict(\n",
    "    n_estimators = 200,\n",
    "    max_depth  = 3,\n",
    "    min_samples_split = 2,\n",
    "    min_samples_leaf  = 2,\n",
    "    max_features = \"sqrt\",\n",
    "    class_weight = \"balanced\",\n",
    "    random_state = SEED,\n",
    "    n_jobs = -1,\n",
    ")\n",
    "BAGGING_N_ESTIMATORS = 10\n",
    "\n",
    "# 输出目录\n",
    "OUT_DIR_FIGS = \"/content/drive/My Drive/final_project/ankle_wrist_only/final_outputs/7_2_dev_figs\"\n",
    "OUT_DIR_REPORTS = \"/content/drive/My Drive/final_project/ankle_wrist_only/final_outputs/7_2_dev_reports\"\n",
    "os.makedirs(OUT_DIR_FIGS, exist_ok=True)\n",
    "os.makedirs(OUT_DIR_REPORTS, exist_ok=True)\n",
    "\n",
    "# 工具函数\n",
    "def pick_columns_by_prefix(df, prefixes):\n",
    "    return [c for c in df.columns if any(c.startswith(p) for p in prefixes)]\n",
    "\n",
    "def build_modality_view(df, modality, subject_col, activity_col, demo_cat_cols, demo_num_cols):\n",
    "\n",
    "    d = df.copy().replace([np.inf, -np.inf], np.nan)\n",
    "    assert subject_col in d.columns, f\"缺少列：{subject_col}\"\n",
    "    assert activity_col in d.columns, f\"缺少列：{activity_col}\"\n",
    "\n",
    "    wrist_cols = pick_columns_by_prefix(d, [\"wrist_\"])\n",
    "    ankle_cols = pick_columns_by_prefix(d, [\"ankle_\"])\n",
    "\n",
    "    if modality == \"wrist\":\n",
    "        feat_cols = wrist_cols\n",
    "    elif modality == \"ankle\":\n",
    "        feat_cols = ankle_cols\n",
    "    elif modality == \"dual\": \n",
    "        feat_cols = wrist_cols + [c for c in ankle_cols if c not in wrist_cols]\n",
    "    else:\n",
    "        raise ValueError(\"modality 必须是 'wrist' | 'ankle' | 'dual'\")\n",
    "\n",
    "    demo_cat = [c for c in (demo_cat_cols or []) if c in d.columns]\n",
    "    demo_num = [c for c in (demo_num_cols or []) if c in d.columns]\n",
    "\n",
    "    # 数值特征管道（含缺失填充）\n",
    "    num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "    transformers = [(\"num\", num_pipe, feat_cols)]\n",
    "\n",
    "    # 分类特征 OHE（稠密输出）\n",
    "    if demo_cat:\n",
    "        try:\n",
    "            ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        except TypeError:\n",
    "            ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "        cat_pipe = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", ohe)\n",
    "        ])\n",
    "        transformers.append((\"cat\", cat_pipe, demo_cat))\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers,\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3   # 确保整体返回为 dense（结合上面的 dense OHE）\n",
    "    )\n",
    "\n",
    "    used_cols = feat_cols + demo_cat + demo_num\n",
    "    X_raw = d[used_cols].copy()\n",
    "    y = d[activity_col].astype(str).values\n",
    "    groups = d[subject_col].astype(str).values\n",
    "    meta = d[[subject_col, activity_col]].copy()\n",
    "\n",
    "    return X_raw, y, groups, preprocessor, meta, feat_cols\n",
    "\n",
    "def build_fixed_baseline_pipeline(preprocessor):\n",
    "\n",
    "    rf_base = RandomForestClassifier(**RF_PARAMS)\n",
    "    bag = BaggingClassifier(\n",
    "        estimator = rf_base,\n",
    "        n_estimators = BAGGING_N_ESTIMATORS,\n",
    "        random_state = SEED,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"scaler\", StandardScaler(with_mean=True)),\n",
    "        (\"pca\", PCA(n_components=PCA_N_COMPONENTS, random_state=SEED)),\n",
    "        (\"bag\", bag)\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "def plot_cm_counts_and_norm(y_true, y_pred, labels, title_prefix, out_png_prefix):\n",
    "    # counts\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ConfusionMatrixDisplay(cm, display_labels=labels).plot(ax=ax, cmap=\"Blues\", colorbar=True, values_format=\"d\")\n",
    "    ax.set_title(f\"{title_prefix} — Confusion Matrix (Counts)\")\n",
    "    plt.tight_layout()\n",
    "    png_counts = f\"{OUT_DIR_FIGS}/{out_png_prefix}_CM_counts.png\"\n",
    "    plt.savefig(png_counts, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # normalized (row-wise)\n",
    "    cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ConfusionMatrixDisplay(cm_norm, display_labels=labels).plot(ax=ax, cmap=\"Blues\", colorbar=True, values_format=\".2f\")\n",
    "    ax.set_title(f\"{title_prefix} — Confusion Matrix (Normalized)\")\n",
    "    plt.tight_layout()\n",
    "    png_norm = f\"{OUT_DIR_FIGS}/{out_png_prefix}_CM_normalized.png\"\n",
    "    plt.savefig(png_norm, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return cm, cm_norm, png_counts, png_norm\n",
    "\n",
    "def loso_evaluate_fixed(X_df, y, groups, preprocessor, label_order=None, run_name=\"\"):\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "    metrics_rows = []\n",
    "    y_true_all = np.empty_like(y, dtype=object)\n",
    "    y_pred_all = np.empty_like(y, dtype=object)\n",
    "\n",
    "    # 用固定超参，逐折新建/拟合\n",
    "    for fold_id, (tr, te) in enumerate(logo.split(X_df, y, groups), start=1):\n",
    "        pipe = build_fixed_baseline_pipeline(preprocessor)\n",
    "        pipe.fit(X_df.iloc[tr], y[tr])\n",
    "        pred = pipe.predict(X_df.iloc[te])\n",
    "\n",
    "        y_true_all[te] = y[te]\n",
    "        y_pred_all[te] = pred\n",
    "\n",
    "        row = dict(\n",
    "            fold = fold_id,\n",
    "            subject = \",\".join(sorted(set(groups[te]))),\n",
    "            acc = accuracy_score(y[te], pred),\n",
    "            balAcc = balanced_accuracy_score(y[te], pred),\n",
    "            macroF1 = f1_score(y[te], pred, average=\"macro\", zero_division=0),\n",
    "            prec = precision_score(y[te], pred, average=\"macro\", zero_division=0),\n",
    "            rec = recall_score(y[te], pred, average=\"macro\", zero_division=0),\n",
    "            n = len(te),\n",
    "        )\n",
    "        metrics_rows.append(row)\n",
    "\n",
    "    folds_df = pd.DataFrame(metrics_rows)\n",
    "    m = folds_df[[\"acc\",\"balAcc\",\"macroF1\",\"prec\",\"rec\"]].mean()\n",
    "    s = folds_df[[\"acc\",\"balAcc\",\"macroF1\",\"prec\",\"rec\"]].std(ddof=1)\n",
    "\n",
    "    labels = sorted(np.unique(y)) if label_order is None else label_order\n",
    "    rep = classification_report(y_true_all, y_pred_all, labels=labels, output_dict=True, zero_division=0)\n",
    "    rep_df = pd.DataFrame(rep).T.reset_index().rename(columns={\"index\":\"class\"})\n",
    "\n",
    "    # 保存报告文件\n",
    "    folds_csv = f\"{OUT_DIR_REPORTS}/DEV_Folds_{run_name}.csv\"\n",
    "    rep_csv = f\"{OUT_DIR_REPORTS}/DEV_Report_{run_name}.csv\"\n",
    "    folds_df.to_csv(folds_csv, index=False)\n",
    "    rep_df.to_csv(rep_csv, index=False)\n",
    "\n",
    "    print(f\"\\n[DEV-LOSO: {run_name}] folds={len(folds_df)} samples={len(y)} subjects={len(np.unique(groups))}\")\n",
    "    print(\"Acc : %.3f ± %.3f\" % (m[\"acc\"],    s[\"acc\"]))\n",
    "    print(\"Balanced Acc : %.3f ± %.3f\" % (m[\"balAcc\"], s[\"balAcc\"]))\n",
    "    print(\"Macro-F1 : %.3f ± %.3f\" % (m[\"macroF1\"], s[\"macroF1\"]))\n",
    "    print(\"Macro-Prec : %.3f ± %.3f\" % (m[\"prec\"],   s[\"prec\"]))\n",
    "    print(\"Macro-Rec : %.3f ± %.3f\" % (m[\"rec\"],    s[\"rec\"]))\n",
    "    print(\"Saved:\", folds_csv)\n",
    "    print(\"Saved:\", rep_csv)\n",
    "\n",
    "    return dict(\n",
    "        folds_df=folds_df, mean=m, std=s,\n",
    "        y_true_all=y_true_all, y_pred_all=y_pred_all,\n",
    "        labels=labels, rep_df=rep_df, rep_csv=rep_csv,\n",
    "    )\n",
    "\n",
    "# 主流程\n",
    "def main():\n",
    "    # 读 DEV（train∪val）\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    val_df = pd.read_csv(VAL_CSV)\n",
    "    DEV_DF = pd.concat([train_df, val_df], ignore_index=True)\n",
    "\n",
    "    # 汇总表（折均值±std）\n",
    "    summary_rows = []\n",
    "\n",
    "    for modality in MODALITIES_TO_RUN:\n",
    "        Xd, yd, gd, pre_d, meta_d, feat_cols = build_modality_view(\n",
    "            DEV_DF, modality, SUBJECT_COL, ACTIVITY_COL,\n",
    "            DEMOGRAPHIC_CAT_COLS, DEMOGRAPHIC_NUM_COLS\n",
    "        )\n",
    "        disp_name = MODALITY_DISPLAY.get(modality, modality)\n",
    "        run_name = f\"LOSO_{disp_name}\"\n",
    "\n",
    "        print(f\"\\n Running LOSO for: {disp_name} | n_samples={len(yd)} | n_features={len(feat_cols)} \")\n",
    "        res = loso_evaluate_fixed(\n",
    "            X_df=Xd, y=yd, groups=gd, preprocessor=pre_d, run_name=run_name\n",
    "        )\n",
    "\n",
    "        # 画并保存 CM（counts + normalized）\n",
    "        title_prefix = f\"{disp_name} [DEV LOSO]\"\n",
    "        out_prefix = f\"DEV_{run_name}\"\n",
    "        cm, cm_norm, png_counts, png_norm = plot_cm_counts_and_norm(\n",
    "            res[\"y_true_all\"], res[\"y_pred_all\"], res[\"labels\"], title_prefix, out_prefix\n",
    "        )\n",
    "        print(\"Saved:\", png_counts)\n",
    "        print(\"Saved:\", png_norm)\n",
    "\n",
    "        # 汇总一行\n",
    "        summary_rows.append({\n",
    "            \"modality\": disp_name,\n",
    "            \"Acc (mean±std)\" : f\"{res['mean']['acc']:.4f} ± {res['std']['acc']:.4f}\",\n",
    "            \"Balanced Acc (mean±std)\": f\"{res['mean']['balAcc']:.4f} ± {res['std']['balAcc']:.4f}\",\n",
    "            \"Macro-F1 (mean±std)\" : f\"{res['mean']['macroF1']:.4f} ± {res['std']['macroF1']:.4f}\",\n",
    "            \"Macro-Prec (mean±std)\" : f\"{res['mean']['prec']:.4f} ± {res['std']['prec']:.4f}\",\n",
    "            \"Macro-Rec (mean±std)\" : f\"{res['mean']['rec']:.4f} ± {res['std']['rec']:.4f}\",\n",
    "            \"n_samples\" : len(yd),\n",
    "            \"n_features\" : len(feat_cols),\n",
    "        })\n",
    "\n",
    "    # 打印与保存汇总表\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    print(\"\\nSummary (DEV LOSO)\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    summary_csv = f\"{OUT_DIR_REPORTS}/DEV_Summary_LOSO.csv\"\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(\"Saved:\", summary_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOXqGW+C8755Zz2Ju+E8vVT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
